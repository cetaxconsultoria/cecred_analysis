{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First contact\n",
    "\n",
    "The purpose of this analysis is to find out which products to recommend to new users.\n",
    "\n",
    "This is done by training a model that figures out the relationship between the users' profiles and their preferences of a given product.\n",
    "\n",
    "**The main use of this model is to provide a warm start for our collaborative recommender**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "from scipy.stats import pearsonr\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, AdaBoostClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.decomposition import TruncatedSVD # Plays nicely with sparse data\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('../..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "from data.data import clean_data\n",
    "\n",
    "\n",
    "disable_grid_search = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate the data\n",
    "\n",
    "The data is generated by extracting the profile features from the dataset, by doing some feature mining and engineering. Then, another table is created to hold the preferences by user. This will be used as a target to our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Maronato/pyenvs/_Users_Maronato_Documents_Cetax_cecred/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2728: DtypeWarning: Columns (78) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Get raw data\n",
    "raw_data = pd.read_csv(\"../../data/datasets/raw.csv\", sep=\"|\")\n",
    "# Get list of names\n",
    "names = pd.read_csv(\"../../data/datasets/names.csv\")\n",
    "# Get list of product column names\n",
    "product_names = list(filter(lambda x: x.startswith(\"QTDE\"), raw_data.columns.values))\n",
    "\n",
    "# Extract label columns\n",
    "labels_raw = raw_data[product_names]\n",
    "\n",
    "# Drop labels that only have one type of label\n",
    "labels = labels_raw.drop(labels_raw.apply(lambda x: x.nunique())[labels_raw.apply(lambda x: x.nunique())==1].index, axis=1)\n",
    "\n",
    "# Remove labels from feature table\n",
    "features_raw = raw_data.drop(product_names, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean features\n",
    "features = clean_data(features_raw)\n",
    "\n",
    "# Note that every column in features e of type np.integer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A deep look at the data\n",
    "Let's look at our features first. What are them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['COOP_NMRESCOP', 'COOP_SKCOOPERATIVA', 'COOP_NRENDCOP',\n",
       "       'AGENCIA_NMRESAGE', 'AGENCIA_DSENDCOP', 'AGENCIA_NMBAIRRO',\n",
       "       'AGENCIA_NMCIDADE', 'DSDRISGP', 'DSENDERE', 'NRENDERE', 'NMBAIRRO',\n",
       "       'NMCIDADE', 'DSESCOLA', 'DSESTCVL', 'DSGRUPORENDAFAT', 'DSINADIMPL',\n",
       "       'DSINPESSOA', 'DSMOTIDEM', 'DSPROFTL', 'DSRESTR', 'DSSEXO',\n",
       "       'DSSITDCT', 'DSSITDTL', 'DSSPCOUTRASINST', 'DSTIPCTA', 'FLGCIDATU',\n",
       "       'FLGRENDAAUT', 'VL_RENDA_FATANUAL', 'QTFUNCIO', 'CDDSCNAE',\n",
       "       'VL_RENDA_PFPJ', 'CARTAOCRED', 'COBRANCARIA', 'CONSORCIO',\n",
       "       'CONVFOLHAPAGTO', 'EMPRESFINAN', 'SEGRESIDENCIA', 'CESSINTERNET',\n",
       "       'DEBITOAUT', 'LMTDSTTIT', 'LMTTRANSACAO', 'LMTCHESPECIAL',\n",
       "       'SEGVIDA', 'DDA', 'LMTDSRCHEQ', 'POUPPROG', 'SEGAUTO',\n",
       "       'DOMICBANCARIO', 'APLICACAO', 'RRECBFOLHAPAGTO', 'PLANOCOTAS',\n",
       "       'UTILCOBRANCA', 'CONTRATOS_PREJUIZO', 'VL_DOMICBANC',\n",
       "       'VL_PLANOCOTAS', 'VL_PLANOPOUPPROG', 'VL_LMTCARTAOCREDITO',\n",
       "       'VL_LMTCHESPECIAL', 'VL_EMP_FINAN', 'VL_APLICACAO',\n",
       "       'VL_COTASCAPITAL', 'VL_POUPPROG', 'VL_CONSORCIO', 'VL_RECEB_FOLHA',\n",
       "       'VL_LMTTRANSACAO', 'VL_LMTDESCTTIT', 'VL_LMTDESCTCHEQ',\n",
       "       'VL_COBBANC', 'VL_SEG_VIDA', 'VL_SEG_RES', 'VL_SEG_AUTO',\n",
       "       'VL_CONV_FOLHA_PAGTO', 'VL_DEBITOAUT', 'QTD_TOTAL_PROD',\n",
       "       'DSTIPOVINCULACAO', 'DTREFERENCIA'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_raw.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From those, keep in mind that some of them are going to be removed by our `clean_data` function.\n",
    "\n",
    "We are going to remove features that represent just a single value, or that likely do not matter, like `AGENCIA_NMBAIRRO`.\n",
    "\n",
    "We are also going to remove the ones that start with `VL`, since they represent the amount of product purchased and are analogous to our labels\n",
    "\n",
    "We end up with the following features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['COOP_NMRESCOP', 'COOP_SKCOOPERATIVA', 'COOP_NRENDCOP', 'DSDRISGP',\n",
       "       'NMCIDADE', 'DSGRUPORENDAFAT', 'DSINADIMPL', 'DSMOTIDEM', 'DSRESTR',\n",
       "       'DSSITDCT', 'DSSITDTL', 'DSSPCOUTRASINST', 'DSTIPCTA', 'FLGCIDATU',\n",
       "       'CDDSCNAE', 'CONTRATOS_PREJUIZO', 'DSTIPOVINCULACAO'], dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_data(features_raw, dummify_categorical=False).columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now looking at our labels, we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['QTDE_CONTAS', 'QTDE_PLANOCOTAS', 'QTDE_APLICACAO',\n",
       "       'QTDE_LMTCHESPECIAL', 'QTDE_POUPPROG', 'QTDE_EMPRES_FINAN',\n",
       "       'QTDE_LMTDSTCHEQ', 'QTDE_LMTDSTTIT', 'QTDE_ACESSINTERNET',\n",
       "       'QTDE_LMTTRANSACAO', 'QTDE_CARTAOCRED', 'QTDE_DEBITOAUT',\n",
       "       'QTDE_DDA', 'QTDE_COBBANCARIA', 'QTDE_SEGVIDA',\n",
       "       'QTDE_SEGRESIDENCIA', 'QTDE_SEGAUTO', 'QTDE_CONSORCIO',\n",
       "       'QTDE_CONVFOLHA', 'QTDE_RECEBFOLHA', 'QTDE_DOMICBANC',\n",
       "       'QTDE_UTILCOBRANCA'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_raw.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But most of thoses features are categorical, so whe dummified them. Let's take a look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['DSINADIMPL', 'DSRESTR', 'DSSPCOUTRASINST', ...,\n",
       "       'DSTIPOVINCULACAO_Baixíssima', 'DSTIPOVINCULACAO_Boa',\n",
       "       'DSTIPOVINCULACAO_Média'], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61777, 1458)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of final features\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model the model\n",
    "Now we need to create our model\n",
    "\n",
    "Lets start by defining some helpful constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These columns are the ones dummyfied by our clean_function\n",
    "d_columns = ['COOP_NMRESCOP',\n",
    " 'COOP_SKCOOPERATIVA',\n",
    " 'COOP_NRENDCOP',\n",
    " 'DSDRISGP',\n",
    " 'NMCIDADE',\n",
    " 'DSGRUPORENDAFAT',\n",
    " 'DSMOTIDEM',\n",
    " 'DSSITDCT',\n",
    " 'DSSITDTL',\n",
    " 'DSTIPCTA',\n",
    " 'CDDSCNAE',\n",
    " 'QTD_TOTAL_PROD',\n",
    " 'DSTIPOVINCULACAO']\n",
    "\n",
    "# Lets now select every dummyfied column\n",
    "dummy_columns = []\n",
    "for d in d_columns:\n",
    "    for c in features.columns.values:\n",
    "        if c.startswith(d):\n",
    "            dummy_columns.append(c)\n",
    "\n",
    "# And the remaining columns\n",
    "not_dummy_columns = [i for i in features.columns.values if i not in dummy_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DSINADIMPL', 'DSRESTR', 'DSSPCOUTRASINST', 'FLGCIDATU', 'CONTRATOS_PREJUIZO']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_dummy_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our dummy_columns list represents the columns created from the \"dummyfication\" method, they probably represent a very sparse matrix. We can test it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00820828586659646"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_columns_df = features[dummy_columns].to_sparse(fill_value=0)\n",
    "dummy_columns_df.density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, it is pretty sparse.\n",
    "\n",
    "Let's compare it against our `not_dummy_columns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9282937015394078"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not_dummy_columns_df = features[not_dummy_columns].to_sparse(fill_value=0)\n",
    "not_dummy_columns_df.density"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not sparse at all.\n",
    "\n",
    "So, since we have a very heterogeneous dataset, let's treat it as one and divide our features into two categories\n",
    "\n",
    "One is a sparse, dummyfied set and another a dense, not dummified set\n",
    "\n",
    "To exploit that, let's create a custom transformer that selects columns from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ColumnsSelector(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Selects a column from the data passed (as a list)\"\"\"\n",
    "    def __init__(self, columns):\n",
    "        self.columns = columns\n",
    "\n",
    "    def fit(self, x, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, dataframe):\n",
    "        return dataframe[self.columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create some pipelines. We'll create some simple ones and the a big, complex one. Let's see how they compare\n",
    "\n",
    "Let's start by creating some naive classifiers that take raw data\n",
    "\n",
    "I also included some hyperparameter options for our grid search later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipes = {\n",
    "    \"nb_pipe\": {\n",
    "        'pipe': Pipeline([\n",
    "            ('classifier', BernoulliNB(alpha=1, fit_prior=True))\n",
    "        ]),\n",
    "        'params':\n",
    "            {\n",
    "                'classifier__alpha': [0, 0.5, 0.3, 0.7, 1, 1.5],\n",
    "                'classifier__fit_prior': [True]}\n",
    "    },\n",
    "    \n",
    "    \"rf_pipe\": {\n",
    "        'pipe': Pipeline([\n",
    "            ('classifier', RandomForestClassifier(criterion='entropy', n_estimators=100, oob_score=False))\n",
    "        ]),\n",
    "        'params':\n",
    "        {\n",
    "            'classifier__n_estimators': [5, 10, 20, 100],\n",
    "            'classifier__criterion': ['gini', 'entropy'],\n",
    "            'classifier__oob_score': [True, False]}\n",
    "    },\n",
    "    \n",
    "    \"sv_pipe\": {\n",
    "        'pipe': Pipeline([\n",
    "            ('classifier', LinearSVC(C=1, fit_intercept=True, intercept_scaling=1e-05, tol=0.01))\n",
    "        ]),\n",
    "        'params':\n",
    "        {\n",
    "            'classifier__tol': [1e-4, 1e-2],\n",
    "            'classifier__C': [1, 5, 100],\n",
    "            'classifier__fit_intercept': [True, False],\n",
    "            'classifier__intercept_scaling': [1, 0.1, 1e-5]}\n",
    "    },\n",
    "\n",
    "    \"lr_pipe\": {\n",
    "        'pipe': Pipeline([\n",
    "            ('classifier', LogisticRegression(C=1, fit_intercept=True, intercept_scaling=1, solver='saga', tol=0.01))\n",
    "        ]),\n",
    "        'params':\n",
    "        {\n",
    "            'classifier__tol': [1e-4, 1e-2],\n",
    "            'classifier__C': [1, 1e-5, 5, 100],\n",
    "            'classifier__fit_intercept': [True, False],\n",
    "            'classifier__intercept_scaling': [1, 0.1, 1e-5],\n",
    "            'classifier__solver': ['liblinear', 'saga', 'sag']}\n",
    "    },\n",
    "\n",
    "    \"mlp_pipe\": {\n",
    "        'pipe': Pipeline([\n",
    "            ('classifier', MLPClassifier(early_stopping=True, hidden_layer_sizes=(40, 30, 5), learning_rate='adaptive'))\n",
    "        ]),\n",
    "        'params':\n",
    "        {\n",
    "            'classifier__hidden_layer_sizes': [(40, 30, 5), (40, 10, 5), (40, 20, 5), (40, 20, 10)]}\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And try them out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing nb_pipe\n",
      "Score: 0.739013414489\n",
      "CPU times: user 1.76 s, sys: 141 ms, total: 1.9 s\n",
      "Wall time: 23.9 s\n",
      "\n",
      "Testing lr_pipe\n",
      "Score: 0.810253381112\n",
      "CPU times: user 1.79 s, sys: 148 ms, total: 1.94 s\n",
      "Wall time: 38.7 s\n",
      "\n",
      "Testing sv_pipe\n",
      "Score: 0.809508863862\n",
      "CPU times: user 1.77 s, sys: 139 ms, total: 1.91 s\n",
      "Wall time: 15 s\n",
      "\n",
      "Testing rf_pipe\n",
      "Score: 0.797546086369\n",
      "CPU times: user 2.06 s, sys: 183 ms, total: 2.24 s\n",
      "Wall time: 4min 24s\n",
      "\n",
      "Testing mlp_pipe\n",
      "Score: 0.811856035393\n",
      "CPU times: user 1.86 s, sys: 174 ms, total: 2.03 s\n",
      "Wall time: 55.2 s\n"
     ]
    }
   ],
   "source": [
    "for k, v in pipes.items():\n",
    "    print()\n",
    "    print(\"Testing\", k)\n",
    "    %time print(\"Score:\", cross_val_score(v['pipe'], features, labels['QTDE_EMPRES_FINAN'], cv=10, n_jobs=-1).mean())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the best ones are Logistic Regression, Support Vectors and Multi-layer Perceptrons, in order\n",
    "\n",
    "We can do a grid search to find the best parameters. I've done it already and filled out the best ones above, but you can try the code for yourself if you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "if disable_grid_search:\n",
    "    for k, v in pipes.items():\n",
    "        if not k in list(results):\n",
    "            print(\"Fitting {}\".format(k))\n",
    "            clf = GridSearchCV(v['pipe'], v['params'], cv=3, n_jobs=1, verbose=10)\n",
    "            %time clf.fit(X_train, y_train)\n",
    "            print(\"{} best score: {}\\nbest params: {}\".format(k, clf.best_score_, clf.best_params_))\n",
    "            results[k] = pd.DataFrame(clf.cv_results_)\n",
    "            print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take those and add do some feature engineering like scaling, selection and dimensionality reduction\n",
    "\n",
    "We'll be using FeatureUnion to append engineered features\n",
    "\n",
    "Finally, we'll wrap everything using an ensemble method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline([\n",
    "    # Use FeatureUnion to combine the processed\n",
    "    ('union', FeatureUnion(\n",
    "        transformer_list=[\n",
    "\n",
    "            # Pipeline for scaling and preprocessing not dummified features\n",
    "            ('not_dummy', Pipeline([\n",
    "                ('selector', ColumnsSelector(columns=not_dummy_columns)),\n",
    "                ('scaler', StandardScaler()),\n",
    "            ])),\n",
    "\n",
    "            # Pipeline for scaling and preprocessing dummified features\n",
    "            ('dummy', Pipeline([\n",
    "                ('selector',  ColumnsSelector(columns=dummy_columns)),\n",
    "                ('scaler', StandardScaler(with_mean=False, with_std=False)),\n",
    "            ])),\n",
    "        ],\n",
    "\n",
    "        # weight components in FeatureUnion\n",
    "        transformer_weights={\n",
    "            'not_dummy': 1,\n",
    "            'dummy': 1,\n",
    "        },\n",
    "    )),\n",
    "    # Apply a voting classifier as ensemble method with 3 classifiers    \n",
    "#     ('lr', LogisticRegression(C=1, fit_intercept=True, intercept_scaling=1, solver='saga', tol=0.01))\n",
    "    ('ensemble', VotingClassifier(\n",
    "        estimators=[\n",
    "            ('lr', LogisticRegression(C=1, fit_intercept=True, intercept_scaling=1, solver='saga', tol=0.01)),\n",
    "            ('mlp', MLPClassifier(early_stopping=True, hidden_layer_sizes=(40, 30, 5), learning_rate='adaptive')),\n",
    "            ('lsv', LinearSVC(C=1, fit_intercept=True, intercept_scaling=1e-05, tol=0.01)),\n",
    "        ],\n",
    "        voting='hard'\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That should be robust enough for our purposes.\n",
    "\n",
    "We also should do some more feature engineering and filtering, but let's leave that for another day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate it\n",
    "\n",
    "To check our pipeline, we should run it against all of our products(may take a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating QTDE_PLANOCOTAS\n",
      "\n",
      "Score: 0.938731382607\n",
      "CPU times: user 1.87 s, sys: 259 ms, total: 2.13 s\n",
      "Wall time: 2min 9s\n",
      "\n",
      "Evaluating QTDE_APLICACAO\n",
      "\n",
      "Score: 0.744160937884\n",
      "CPU times: user 1.87 s, sys: 158 ms, total: 2.03 s\n",
      "Wall time: 2min 23s\n",
      "\n",
      "Evaluating QTDE_LMTCHESPECIAL\n",
      "\n",
      "Score: 0.998397450554\n",
      "CPU times: user 1.86 s, sys: 146 ms, total: 2.01 s\n",
      "Wall time: 1min 51s\n",
      "\n",
      "Evaluating QTDE_POUPPROG\n",
      "\n",
      "Score: 0.795603955405\n",
      "CPU times: user 1.87 s, sys: 150 ms, total: 2.02 s\n",
      "Wall time: 2min 29s\n",
      "\n",
      "Evaluating QTDE_EMPRES_FINAN\n",
      "\n",
      "Score: 0.811758877271\n",
      "CPU times: user 1.89 s, sys: 153 ms, total: 2.04 s\n",
      "Wall time: 2min 28s\n",
      "\n",
      "Evaluating QTDE_LMTDSTCHEQ\n",
      "\n",
      "Score: 0.85127157221\n",
      "CPU times: user 1.9 s, sys: 156 ms, total: 2.06 s\n",
      "Wall time: 2min 57s\n",
      "\n",
      "Evaluating QTDE_LMTDSTTIT\n",
      "\n",
      "Score: 0.9126698052\n",
      "CPU times: user 1.88 s, sys: 155 ms, total: 2.04 s\n",
      "Wall time: 2min 39s\n",
      "\n",
      "Evaluating QTDE_ACESSINTERNET\n",
      "\n",
      "Score: 0.950062539175\n",
      "CPU times: user 1.86 s, sys: 132 ms, total: 1.99 s\n",
      "Wall time: 2min 14s\n",
      "\n",
      "Evaluating QTDE_LMTTRANSACAO\n",
      "\n",
      "Score: 0.92738423255\n",
      "CPU times: user 1.86 s, sys: 144 ms, total: 2.01 s\n",
      "Wall time: 2min 16s\n",
      "\n",
      "Evaluating QTDE_CARTAOCRED\n",
      "\n",
      "Score: 0.845266256002\n",
      "CPU times: user 1.86 s, sys: 144 ms, total: 2 s\n",
      "Wall time: 2min 22s\n",
      "\n",
      "Evaluating QTDE_DEBITOAUT\n",
      "\n",
      "Score: 0.812648957998\n",
      "CPU times: user 1.88 s, sys: 133 ms, total: 2.01 s\n",
      "Wall time: 2min 46s\n",
      "\n",
      "Evaluating QTDE_DDA\n",
      "\n",
      "Score: 0.953186467536\n",
      "CPU times: user 1.88 s, sys: 153 ms, total: 2.03 s\n",
      "Wall time: 3min 11s\n",
      "\n",
      "Evaluating QTDE_COBBANCARIA\n",
      "\n",
      "Score: 0.799003081208\n",
      "CPU times: user 1.85 s, sys: 140 ms, total: 1.99 s\n",
      "Wall time: 2min 21s\n",
      "\n",
      "Evaluating QTDE_CONSORCIO\n",
      "\n",
      "Score: 0.958107397115\n",
      "CPU times: user 1.84 s, sys: 144 ms, total: 1.98 s\n",
      "Wall time: 2min 33s\n",
      "\n",
      "Evaluating QTDE_CONVFOLHA\n",
      "\n",
      "Score: 0.974942139338\n",
      "CPU times: user 1.83 s, sys: 149 ms, total: 1.98 s\n",
      "Wall time: 1min 42s\n",
      "\n",
      "Evaluating QTDE_DOMICBANC\n",
      "\n",
      "Score: 0.922543957916\n",
      "CPU times: user 1.85 s, sys: 154 ms, total: 2 s\n",
      "Wall time: 2min 21s\n",
      "\n",
      "Evaluating QTDE_UTILCOBRANCA\n",
      "\n",
      "Score: 0.850106080972\n",
      "CPU times: user 1.85 s, sys: 146 ms, total: 2 s\n",
      "Wall time: 2min 23s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for product in labels.columns.values:\n",
    "    print(\"Evaluating\", product)\n",
    "    label = labels[product]\n",
    "    print()\n",
    "    %time print(\"Score:\", cross_val_score(pipeline, features, label, cv=10, n_jobs=-1).mean())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
